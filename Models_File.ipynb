{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "Models_File.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c916T29R6hw"
      },
      "source": [
        "<h1>Importing Libraries</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o7ZRZlY30lA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdce7a8d-4c41-4720-959c-c03c47d5a2e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JGwvql01EMY",
        "outputId": "6fecbbeb-a6ba-4144-d02a-8190900f06eb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.7/dist-packages (0.14.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.7.3)\n",
            "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.3.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.1->mlxtend) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.1->mlxtend) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmzb62hYR6hx"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE3SwjSKR6h6"
      },
      "source": [
        "<h1>Importing Train Test Files</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4jZbV0GR6h7"
      },
      "source": [
        "train_data = pickle.load(open('/content/drive/MyDrive/instacart-market-basket-analysis/final_data_trainn.pkl','rb'))\n",
        "test_data = pickle.load(open('/content/drive/MyDrive/instacart-market-basket-analysis/final_data_test.pkl','rb'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at_t4iZ_9F0c"
      },
      "source": [
        "<h1>Data & Result Split</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3rh3pw5R6iB"
      },
      "source": [
        "X = train_data.drop('reordered', axis=1)\n",
        "Y = train_data['reordered'].values"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVBL_UspR6iH"
      },
      "source": [
        "# Replacing the infinite values with NaN first and then with the mean value.\n",
        "\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiM3vtSZR6iN"
      },
      "source": [
        "<h1>Preprocessing Data</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLosOGAWR6iO"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "minmax = MinMaxScaler()\n",
        "def normalize(df):\n",
        "    #This function normalizes data by applying min max scaler\n",
        "\n",
        "    result1 = df.copy()\n",
        "    for feature_name in df.columns:\n",
        "        array_values = np.asarray(df[feature_name].values)\n",
        "        array = array_values.reshape(-1,1)\n",
        "        minmax.fit(array)\n",
        "        scaled = minmax.transform(array)\n",
        "        result1[feature_name] = scaled\n",
        "    return result1\n",
        "\n",
        "processed_x = normalize(X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vmhC46MR6iT"
      },
      "source": [
        "<h1>Train Test Split</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BU9xR7mR6iU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ff8d90-9478-4ad7-f4ae-601ef25f8d78"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(processed_x, Y, stratify = Y, test_size=0.2, random_state=14)\n",
        "\n",
        "print(\"Train size\", X_train.shape, Y_train.shape)\n",
        "print(\"Test size\", X_test.shape, Y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size (3024724, 25) (3024724,)\n",
            "Test size (756181, 25) (756181,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZwP6lMjR6ic"
      },
      "source": [
        "<h1>Building Models</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtXqbwShYRtU"
      },
      "source": [
        "#Note\n",
        "\n",
        "1. As there are many models making submission with each of them doesn't make sense and is time consuming.\n",
        "\n",
        "2. So I will look into Validation F1-Score and will pick the model with best Validation F1-Score.\n",
        "\n",
        "3. Will compare validation F1-Score of each model.\n",
        "\n",
        "4. Then will predict the real test data through that model and will create submission file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nixd_90eR6id"
      },
      "source": [
        "<h2> 1. Logistic Regression </h2>\n",
        "\n",
        "<h3> Tuning Logistic Regression</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lge05vuLjvut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d79b5a4-3262-43e4-aa4e-f6b4b7585153"
      },
      "source": [
        "C = [0.001,1,100]\n",
        "for i in C:\n",
        "  lr_temp = LogisticRegression(C=i)\n",
        "  lr_temp.fit(X_train, Y_train)\n",
        "  train_predict = (lr_temp.predict_proba(X_train)[:,1]>=0.1).astype('int')\n",
        "  test_predict = (lr_temp.predict_proba(X_test)[:,1]>=0.1).astype('int')\n",
        "\n",
        "  f1_train = f1_score(train_predict, Y_train)\n",
        "  f1_test = f1_score(test_predict, Y_test)\n",
        "\n",
        "  print(\"Train F1 Score At C = {0} is {1}\".format(i, f1_train))\n",
        "  print(\"Test F1 Score At C = {0} is {1}\".format(i, f1_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1 Score At C = 0.001 is 0.3069966414255283\n",
            "Test F1 Score At C = 0.001 is 0.3067085709851395\n",
            "Train F1 Score At C = 1 is 0.31092603218627923\n",
            "Test F1 Score At C = 1 is 0.3101801068610453\n",
            "Train F1 Score At C = 100 is 0.31089136789169575\n",
            "Test F1 Score At C = 100 is 0.3101805781174407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ToayCi6xO6q"
      },
      "source": [
        "<h3>Logistic Regression With Best Parameter</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w4W0fLcR6if",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f4060c-2de2-465c-dace-c18c4c42e5f6"
      },
      "source": [
        "lr = LogisticRegression(C=1)\n",
        "lr.fit(X_train, Y_train)\n",
        "\n",
        "train_pred = (lr.predict_proba(X_train)[:, 1] >= 0.1).astype('int')\n",
        "test_pred = (lr.predict_proba(X_test)[:, 1] >= 0.1).astype('int')\n",
        "\n",
        "f1_train = f1_score(train_pred, Y_train)\n",
        "f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "print(\"Train F1 Score:\", f1_train)\n",
        "print(\"Validation F1 Score:\", f1_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1 Score: 0.31092603218627923\n",
            "Validation F1 Score: 0.3101801068610453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj83GHAoR6ij"
      },
      "source": [
        "<h2> 2. Decision Tree </h2>\n",
        "\n",
        "<h3>Tuning Decision Tree</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5P1472mR6ik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11dcebfe-9a79-4b3f-85a5-01946cb7345a"
      },
      "source": [
        "depth = [3, 5, 7]\n",
        "splits = [50,100,300]\n",
        "\n",
        "for i in depth:\n",
        "    for j in splits:\n",
        "        dtree = DecisionTreeClassifier(max_depth = i, min_samples_split = j)\n",
        "        dtree.fit(X_train,Y_train)\n",
        "\n",
        "        train_pred = (dtree.predict_proba(X_train)[:, 1] >= 0.1).astype('int')\n",
        "        test_pred = (dtree.predict_proba(X_test)[:, 1] >= 0.1).astype('int')\n",
        "\n",
        "        f1_train = f1_score(train_pred, Y_train)\n",
        "        f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "        print(\"Train F1 Score At Depth {0} & Minimum Split {1} is {2}\".format(i,j, f1_train))\n",
        "        print(\"Test F1 Score At Depth {0} & Minimum Split {1} is {2}\".format(i,j, f1_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1 Score At Depth 3 & Minimum Split 5 is 0.2743777273744212\n",
            "Test F1 Score At Depth 3 & Minimum Split 5 is 0.2747626874686363\n",
            "Train F1 Score At Depth 3 & Minimum Split 20 is 0.2743777273744212\n",
            "Test F1 Score At Depth 3 & Minimum Split 20 is 0.2747626874686363\n",
            "Train F1 Score At Depth 3 & Minimum Split 50 is 0.2743777273744212\n",
            "Test F1 Score At Depth 3 & Minimum Split 50 is 0.2747626874686363\n",
            "Train F1 Score At Depth 3 & Minimum Split 100 is 0.2743777273744212\n",
            "Test F1 Score At Depth 3 & Minimum Split 100 is 0.2747626874686363\n",
            "Train F1 Score At Depth 3 & Minimum Split 300 is 0.2743777273744212\n",
            "Test F1 Score At Depth 3 & Minimum Split 300 is 0.2747626874686363\n",
            "Train F1 Score At Depth 3 & Minimum Split 500 is 0.2743777273744212\n",
            "Test F1 Score At Depth 3 & Minimum Split 500 is 0.2747626874686363\n",
            "Train F1 Score At Depth 5 & Minimum Split 5 is 0.30772668137912546\n",
            "Test F1 Score At Depth 5 & Minimum Split 5 is 0.3066342812422703\n",
            "Train F1 Score At Depth 5 & Minimum Split 20 is 0.30772668137912546\n",
            "Test F1 Score At Depth 5 & Minimum Split 20 is 0.3066342812422703\n",
            "Train F1 Score At Depth 5 & Minimum Split 50 is 0.30772668137912546\n",
            "Test F1 Score At Depth 5 & Minimum Split 50 is 0.3066342812422703\n",
            "Train F1 Score At Depth 5 & Minimum Split 100 is 0.30772668137912546\n",
            "Test F1 Score At Depth 5 & Minimum Split 100 is 0.3066342812422703\n",
            "Train F1 Score At Depth 5 & Minimum Split 300 is 0.30772668137912546\n",
            "Test F1 Score At Depth 5 & Minimum Split 300 is 0.3066342812422703\n",
            "Train F1 Score At Depth 5 & Minimum Split 500 is 0.30772668137912546\n",
            "Test F1 Score At Depth 5 & Minimum Split 500 is 0.3066342812422703\n",
            "Train F1 Score At Depth 7 & Minimum Split 5 is 0.30559922899580483\n",
            "Test F1 Score At Depth 7 & Minimum Split 5 is 0.30451935382791645\n",
            "Train F1 Score At Depth 7 & Minimum Split 20 is 0.30559922899580483\n",
            "Test F1 Score At Depth 7 & Minimum Split 20 is 0.30451935382791645\n",
            "Train F1 Score At Depth 7 & Minimum Split 50 is 0.30559922899580483\n",
            "Test F1 Score At Depth 7 & Minimum Split 50 is 0.30451935382791645\n",
            "Train F1 Score At Depth 7 & Minimum Split 100 is 0.30559922899580483\n",
            "Test F1 Score At Depth 7 & Minimum Split 100 is 0.30451935382791645\n",
            "Train F1 Score At Depth 7 & Minimum Split 300 is 0.30559922899580483\n",
            "Test F1 Score At Depth 7 & Minimum Split 300 is 0.30451935382791645\n",
            "Train F1 Score At Depth 7 & Minimum Split 500 is 0.30559922899580483\n",
            "Test F1 Score At Depth 7 & Minimum Split 500 is 0.30451935382791645\n",
            "Train F1 Score At Depth 10 & Minimum Split 5 is 0.30703791936962394\n",
            "Test F1 Score At Depth 10 & Minimum Split 5 is 0.303304167626065\n",
            "Train F1 Score At Depth 10 & Minimum Split 20 is 0.3070195282820754\n",
            "Test F1 Score At Depth 10 & Minimum Split 20 is 0.30332987969838254\n",
            "Train F1 Score At Depth 10 & Minimum Split 50 is 0.306986183720203\n",
            "Test F1 Score At Depth 10 & Minimum Split 50 is 0.3033259232080806\n",
            "Train F1 Score At Depth 10 & Minimum Split 100 is 0.3069268929080481\n",
            "Test F1 Score At Depth 10 & Minimum Split 100 is 0.3033158311155866\n",
            "Train F1 Score At Depth 10 & Minimum Split 300 is 0.3068832541083063\n",
            "Test F1 Score At Depth 10 & Minimum Split 300 is 0.3033273167890351\n",
            "Train F1 Score At Depth 10 & Minimum Split 500 is 0.30690386353580257\n",
            "Test F1 Score At Depth 10 & Minimum Split 500 is 0.3034305631994129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5bZ94mHklgu"
      },
      "source": [
        "<h3>Decision Tree With Best Parameter</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IxqyYwYR6it",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f88b48f-ec71-4723-ee1f-cd1ebfea860d"
      },
      "source": [
        "dtree_tuned = DecisionTreeClassifier(max_depth=10, min_samples_split = 500, random_state=21)\n",
        "dtree_tuned.fit(X_train, Y_train)\n",
        "train_pred = (dtree_tuned.predict_proba(X_train)[:, 1] >= 0.1).astype('int')\n",
        "test_pred = (dtree_tuned.predict_proba(X_test)[:, 1] >= 0.1).astype('int')\n",
        "\n",
        "f1_train = f1_score(train_pred, Y_train)\n",
        "f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "print(\"Train F1 Score:\", f1_train)\n",
        "print(\"Test F1 Score:\", f1_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1 Score: 0.32804105909439757\n",
            "Test F1 Score: 0.32022944099562056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0PRKuhHR6i4"
      },
      "source": [
        "<h2> 3. Random Forest </h2>\n",
        "\n",
        "<h3>Tuning Random Forest</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVNa60BBhl2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f582d2cd-d5af-428e-9b0c-c2e270f09cea"
      },
      "source": [
        "rf= RandomForestClassifier()\n",
        "n_estimators = [50,100,300]\n",
        "max_depth = [3,5,7]\n",
        "for i in n_estimators:\n",
        "    print(\"Estimator :\",i)\n",
        "    for j in max_depth:\n",
        "        print(\"Depth :\",j)\n",
        "        rf_tuned = RandomForestClassifier(max_depth=j, n_estimators = i)\n",
        "        rf_tuned.fit(X_train, Y_train)\n",
        "\n",
        "        train_pred = (rf_tuned.predict_proba(X_train)[:, 1] >= 0.1).astype('int')\n",
        "        test_pred = (rf_tuned.predict_proba(X_test)[:, 1] >= 0.1).astype('int')\n",
        "\n",
        "        f1_train = f1_score(train_pred, Y_train)\n",
        "        f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "        print(\"Train F1 Score:\", f1_train)\n",
        "        print(\"Test F1 Score:\", f1_test)\n",
        "    print(\"_\"*40)   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimator : 10\n",
            "Depth : 3\n",
            "Train F1 Score: 0.28109909451122816\n",
            "Test F1 Score: 0.281397527999643\n",
            "Depth : 5\n",
            "Train F1 Score: 0.29492718425918824\n",
            "Test F1 Score: 0.2939154114543443\n",
            "Depth : 7\n",
            "Train F1 Score: 0.3147034570744003\n",
            "Test F1 Score: 0.31293574487599\n",
            "Depth : 10\n",
            "Train F1 Score: 0.32664776197706547\n",
            "Test F1 Score: 0.31899101853621253\n",
            "________________________________________\n",
            "Estimator : 50\n",
            "Depth : 3\n",
            "Train F1 Score: 0.28458758393848205\n",
            "Test F1 Score: 0.2852084022642117\n",
            "Depth : 5\n",
            "Train F1 Score: 0.3077378578593095\n",
            "Test F1 Score: 0.30680448166663987\n",
            "Depth : 7\n",
            "Train F1 Score: 0.3153004063429908\n",
            "Test F1 Score: 0.31369295892577487\n",
            "Depth : 10\n",
            "Train F1 Score: 0.3287738816658795\n",
            "Test F1 Score: 0.3211972814023204\n",
            "________________________________________\n",
            "Estimator : 100\n",
            "Depth : 3\n",
            "Train F1 Score: 0.2914878514167378\n",
            "Test F1 Score: 0.2908020603384842\n",
            "Depth : 5\n",
            "Train F1 Score: 0.3092073921646533\n",
            "Test F1 Score: 0.3081204228516472\n",
            "Depth : 7\n",
            "Train F1 Score: 0.31470620392352866\n",
            "Test F1 Score: 0.31299346079203133\n",
            "Depth : 10\n",
            "Train F1 Score: 0.3281050254525969\n",
            "Test F1 Score: 0.3214220295518378\n",
            "________________________________________\n",
            "Estimator : 300\n",
            "Depth : 3\n",
            "Train F1 Score: 0.2941177735765459\n",
            "Test F1 Score: 0.29314384284647665\n",
            "Depth : 5\n",
            "Train F1 Score: 0.3092993086427565\n",
            "Test F1 Score: 0.30794594893073224\n",
            "Depth : 7\n",
            "Train F1 Score: 0.31467362577992586\n",
            "Test F1 Score: 0.3130632383383399\n",
            "Depth : 10\n",
            "Train F1 Score: 0.3284370541230114\n",
            "Test F1 Score: 0.3212610675146995\n",
            "________________________________________\n",
            "Estimator : 500\n",
            "Depth : 3\n",
            "Train F1 Score: 0.2884795831993648\n",
            "Test F1 Score: 0.28804205452417964\n",
            "Depth : 5\n",
            "Train F1 Score: 0.3087109678189743\n",
            "Test F1 Score: 0.3078608165597816\n",
            "Depth : 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Bmw0n-kuCY"
      },
      "source": [
        "<h3>Random Forest With Best Parameter</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKH3725NR6jG"
      },
      "source": [
        "rf_tuned = RandomForestClassifier(max_depth=7, n_estimators = 500)\n",
        "rf_tuned.fit(X_train, Y_train)\n",
        "\n",
        "train_pred = (rf_tuned.predict_proba(X_train)[:, 1] >= 0.21).astype('int')\n",
        "test_pred = (rf_tuned.predict_proba(X_test)[:, 1] >= 0.21).astype('int')\n",
        "\n",
        "f1_train = f1_score(train_pred, Y_train)\n",
        "f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "print(\"Train F1 Score:\", f1_train)\n",
        "print(\"Test F1 Score:\", f1_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV9EZmggnY-V"
      },
      "source": [
        "<h2> 4. Light GBM</h2>\n",
        "\n",
        "<h3>Tuning Light GBM</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tV_cZq0R6jm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a2a39b-757b-45c3-9501-823a47b029bc"
      },
      "source": [
        "#Since GBDT was too slow when it comes to hyper-parameter tuning. So didn't used it.\n",
        "#And since Light GBM is successor to GBDT and also fast then it so using it instead of GBDT\n",
        "\n",
        "import lightgbm as lgb\n",
        "lgb_tune = lgb.LGBMClassifier(boosting_type='gbdt')\n",
        "\n",
        "estimator = [10,50,100,300,500]\n",
        "depths = [3,5,7,10]\n",
        "\n",
        "for i in depths:\n",
        "    for j in estimator:\n",
        "        lgb_model = lgb.LGBMClassifier(boosting_type='gbdt', n_estimators=j, max_depth = i)\n",
        "        lgb_model.fit(X_train,Y_train)\n",
        "\n",
        "        train_pred = (lgb_model.predict_proba(X_train)[:, 1] >= 0.1).astype('int')\n",
        "        test_pred = (lgb_model.predict_proba(X_test)[:, 1] >= 0.1).astype('int')\n",
        "\n",
        "        f1_train = f1_score(train_pred, Y_train)\n",
        "        f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "        print(\"Train F1 Score At Depth {0} & Minimum Split {1} is {2}\".format(i,j, f1_train))\n",
        "        print(\"Test F1 Score At Depth {0} & Minimum Split {1} is {2}\".format(i,j, f1_test))\n",
        "    print(\"_\"*35)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1 Score At Depth 3 & Minimum Split 10 is 0.3020379760532217\n",
            "Test F1 Score At Depth 3 & Minimum Split 10 is 0.30175365468782567\n",
            "Train F1 Score At Depth 3 & Minimum Split 50 is 0.3060937913503412\n",
            "Test F1 Score At Depth 3 & Minimum Split 50 is 0.3066379000359583\n",
            "Train F1 Score At Depth 3 & Minimum Split 100 is 0.3089156539023571\n",
            "Test F1 Score At Depth 3 & Minimum Split 100 is 0.3089804391853948\n",
            "Train F1 Score At Depth 3 & Minimum Split 300 is 0.3106864493468638\n",
            "Test F1 Score At Depth 3 & Minimum Split 300 is 0.31026946183497045\n",
            "Train F1 Score At Depth 3 & Minimum Split 500 is 0.3115562967268355\n",
            "Test F1 Score At Depth 3 & Minimum Split 500 is 0.310597299719564\n",
            "___________________________________\n",
            "Train F1 Score At Depth 5 & Minimum Split 10 is 0.30899596895388987\n",
            "Test F1 Score At Depth 5 & Minimum Split 10 is 0.308244640809756\n",
            "Train F1 Score At Depth 5 & Minimum Split 50 is 0.3104333163591114\n",
            "Test F1 Score At Depth 5 & Minimum Split 50 is 0.3095952705775352\n",
            "Train F1 Score At Depth 5 & Minimum Split 100 is 0.31217505893510983\n",
            "Test F1 Score At Depth 5 & Minimum Split 100 is 0.31079791689427877\n",
            "Train F1 Score At Depth 5 & Minimum Split 300 is 0.31460376117569894\n",
            "Test F1 Score At Depth 5 & Minimum Split 300 is 0.3112075031009045\n",
            "Train F1 Score At Depth 5 & Minimum Split 500 is 0.3165626420940568\n",
            "Test F1 Score At Depth 5 & Minimum Split 500 is 0.31163047105076086\n",
            "___________________________________\n",
            "Train F1 Score At Depth 7 & Minimum Split 10 is 0.30966855500930235\n",
            "Test F1 Score At Depth 7 & Minimum Split 10 is 0.3091369575370502\n",
            "Train F1 Score At Depth 7 & Minimum Split 50 is 0.31096497910350807\n",
            "Test F1 Score At Depth 7 & Minimum Split 50 is 0.31025633548161324\n",
            "Train F1 Score At Depth 7 & Minimum Split 100 is 0.3124618741548486\n",
            "Test F1 Score At Depth 7 & Minimum Split 100 is 0.3108514226805626\n",
            "Train F1 Score At Depth 7 & Minimum Split 300 is 0.315594616103249\n",
            "Test F1 Score At Depth 7 & Minimum Split 300 is 0.31123910924932\n",
            "Train F1 Score At Depth 7 & Minimum Split 500 is 0.318040521055174\n",
            "Test F1 Score At Depth 7 & Minimum Split 500 is 0.31154456891821675\n",
            "___________________________________\n",
            "Train F1 Score At Depth 10 & Minimum Split 10 is 0.3100523980880567\n",
            "Test F1 Score At Depth 10 & Minimum Split 10 is 0.30949502960881287\n",
            "Train F1 Score At Depth 10 & Minimum Split 50 is 0.3112033838754865\n",
            "Test F1 Score At Depth 10 & Minimum Split 50 is 0.31022811319311105\n",
            "Train F1 Score At Depth 10 & Minimum Split 100 is 0.31273644618421004\n",
            "Test F1 Score At Depth 10 & Minimum Split 100 is 0.3108716558838958\n",
            "Train F1 Score At Depth 10 & Minimum Split 300 is 0.3162829146520103\n",
            "Test F1 Score At Depth 10 & Minimum Split 300 is 0.31135716338266906\n",
            "Train F1 Score At Depth 10 & Minimum Split 500 is 0.31931750706762463\n",
            "Test F1 Score At Depth 10 & Minimum Split 500 is 0.311334664971854\n",
            "___________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBt-FJj0a6rp"
      },
      "source": [
        "<h3>Light GBM With Best Parameters</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I_5orhDRjCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22effff3-9933-4198-8fa8-d9c57ac249ca"
      },
      "source": [
        "lgb_tuned = lgb.LGBMClassifier(boosting_type='gbdt', n_estimators=500, max_depth=10, random_state=21)\n",
        "\n",
        "lgb_tuned.fit(X_train, Y_train)\n",
        "\n",
        "train_pred = (lgb_tuned.predict_proba(X_train)[:, 1] >= 0.1).astype('int')\n",
        "test_pred = (lgb_tuned.predict_proba(X_test)[:, 1] >= 0.1).astype('int')\n",
        "\n",
        "f1_train = f1_score(train_pred, Y_train)\n",
        "f1_test = f1_score(test_pred, Y_test)\n",
        "\n",
        "print(\"Train F1 Score:\", f1_train)\n",
        "print(\"Test F1 Score:\", f1_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train F1 Score: 0.31927604671064946\n",
            "Test F1 Score: 0.3115880451755819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKOhWFDuLK_Y"
      },
      "source": [
        "pickle.dump((predicted_df),open('/content/drive/MyDrive/instacart-market-basket-analysis/base_model_predicted_df.pkl','wb'))\n",
        "pickle.dump((models),open('/content/drive/MyDrive/instacart-market-basket-analysis/base_models.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I41I8j7_h08B"
      },
      "source": [
        "<h2>Feature Importance</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ACGsPmdh7yI"
      },
      "source": [
        "lgb.plot_importance(lgb_tuned)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSCdXRAGwgVB"
      },
      "source": [
        "**Observation**\n",
        "\n",
        "1. Although every model has almost similar results on both train and validation.\n",
        "\n",
        "2. But still Light GBM has bit better results. \n",
        "\n",
        "3. Will create final prediction data with Light GBM\n",
        "\n",
        "<h2>Function To Predict On Test Data </h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkZ_ZDiNyC-c"
      },
      "source": [
        "test_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "test_data.fillna(X.mean(), inplace=True)\n",
        "\n",
        "final_test = normalize(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqR_kE8Yv5jH"
      },
      "source": [
        "# This function performs prediction on test data by taking the model, test data and dataframe as input\n",
        "\n",
        "def predict_final(data_point, model):\n",
        "  new_data = data_point.copy()\n",
        "      new_data['prediction'] = (model.predict_proba(data_point)[:, 1] >= 0.1).astype('int')\n",
        "      new_data = new_data.reset_index()\n",
        "\n",
        "  final_test_data = new_data[['product_id', 'user_id', 'prediction']]\n",
        "\n",
        "  # We are getting the user_id and order_id which belongs to \"Test Set\"\n",
        "  orders = pd.read_csv('/content/drive/MyDrive/instacart-market-basket-analysis/orders.csv')\n",
        "  test_from_order = orders.loc[orders['eval_set']=='test',['user_id','order_id']]\n",
        "\n",
        "  # Calling the predict function by passing the test data and model by which prediction is to be done\n",
        "  # Merging the whole data with real test data using user_id which gives us 75000 test points\n",
        "\n",
        "  \n",
        "  predicted_results = pd.merge(final_test_data, test_from_order, how='left', on='user_id')\n",
        "  predicted_results = predicted_results.drop('user_id',axis=1)\n",
        "  print(predicted_results.isnull().any().sum())\n",
        "\n",
        "  return predicted_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg37EczO2Ymu"
      },
      "source": [
        "<h2>Creating the submission file with the final dataframe</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH2f7rNt1-Dk"
      },
      "source": [
        "# This function takes the final dataframe and creates the submission file\n",
        "\n",
        "def create_submission_file(final_df):\n",
        "    user_product = dict()\n",
        "\n",
        "    for row in tqdm(final_df.itertuples()):\n",
        "        if row.prediction== 1:\n",
        "            try:\n",
        "                user_product[row.order_id] += ' ' + str(row.product_id)\n",
        "            except:\n",
        "                user_product[row.order_id] = str(row.product_id)\n",
        "\n",
        "    for order in final_df.order_id:\n",
        "        if order not in user_product:\n",
        "            user_product[order] = 'None'\n",
        "\n",
        "    sub = pd.DataFrame.from_dict(user_product, orient='index')\n",
        "    #Reset index\n",
        "    sub.reset_index(inplace=True)\n",
        "    #Set column names\n",
        "    sub.columns = ['order_id', 'products']\n",
        "    \n",
        "    return sub\n",
        "\n",
        "def final_predict_function(final_df):\n",
        "    user_product = dict()\n",
        "\n",
        "    for row in tqdm(final_df.itertuples()):\n",
        "        if row.prediction== 1:\n",
        "            try:\n",
        "                user_product[row.order_id] += ' ' + str(row.product_id)\n",
        "            except:\n",
        "                user_product[row.order_id] = str(row.product_id)\n",
        "\n",
        "    for order in final_df.order_id:\n",
        "        if order not in user_product:\n",
        "            user_product[order] = 'None'    \n",
        "    return user_product            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyg8T8cY1vyu"
      },
      "source": [
        "<h2>Prediction & Submission File By Each Model</h2>\n",
        "\n",
        "<h3>1. Logistic Regression</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ew51ssp1sEP"
      },
      "source": [
        "lr_predicted_df = predict_final(final_test, lr)\n",
        "lr_submission_file = create_submission_file(lr_predicted_df)\n",
        "lr_submission_file.to_csv('/content/drive/MyDrive/instacart-market-basket-analysis/submission files/logistic_regression_submission.csv',index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOD0W1iTv3qP"
      },
      "source": [
        "print(\"F1 Score on Test Data From Kaggle 0.359470\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFFeYXBr6uBc"
      },
      "source": [
        "<h3>2. Decision Tree</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjqdCEpC68cu"
      },
      "source": [
        "dtree_predicted_df = predict_final(final_test, dtree_tuned)\n",
        "dtree_submission_file = create_submission_file(dtree_predicted_df)\n",
        "\n",
        "dtree_submission_file.to_csv('/content/drive/MyDrive/instacart-market-basket-analysis/submission files/Decision_Tree_Submission.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBTnwtvLwBpu"
      },
      "source": [
        "print(\"F1 Score on Test Data From Kaggle 0.366460\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWD6XS847T0Z"
      },
      "source": [
        "<h3>3. Random Forest</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLzh8_uNnMax"
      },
      "source": [
        "random_forest_predicted_df = predict_final(final_test, rf_tuned)\n",
        "random_forest_submission_file = create_submission_file(random_forest_predicted_df)\n",
        "\n",
        "random_forest_submission_file.to_csv('/content/drive/MyDrive/instacart-market-basket-analysis/submission files/random_forest_submission.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVtrfyM1thDB"
      },
      "source": [
        "print(\"F1 Score on Test Data From Kaggle 0.366450\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3d5fv3m7ZWJ"
      },
      "source": [
        "<h3>4. Light GBM</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qY-Uljy68p-"
      },
      "source": [
        "lgb_predicted_df = predict_final(final_test, lgb_tuned)\n",
        "lgb_submission_file = create_submission_file(lgb_predicted_df)\n",
        "\n",
        "lgb_submission_file.to_csv('/content/drive/MyDrive/instacart-market-basket-analysis/submission files/light_gbm_submission.csv', index=False, header=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuqpTD78wEBy"
      },
      "source": [
        "print(\"F1 Score on Test Data From Kaggle 0.363680\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j9Wc9YAt11t"
      },
      "source": [
        "<h1>Comparing Results Of Each Model</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXeL6e0DxJtv"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Model\", \"Train F1 Score\", \"Validation F1 Score\", \"Kaggle Test F1 Score\"]\n",
        "table.add_row([\"Logistic Regression\", 0.414431, 0.415396, 0.359470])\n",
        "table.add_row([\"Decision Tree\", 0.425405, 0.423107, 0.366460])           \n",
        "table.add_row([\"Random Forest\", 0.425082, 0.422441, 0.366450])\n",
        "table.add_row([\"Light GBM\", 0.432666, 0.428093, 0.363680])\n",
        "table.add_row([\"Stacked Model\",  0.298419, 0.294584, 0.255930])\n",
        "table.add_row([\"Meta Classifier\",  0.294019, 0.295305, 0.28001])\n",
        "table.add_row([\"Multi Level Perceptron\",  0.241301, 0.081301, 0.063320])\n",
        "\n",
        "print(table) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQobqgvshtKA"
      },
      "source": [
        "<h1> Observation</h1>\n",
        "\n",
        "Decision Tree is the best model with Test F1-Score of 0.36646\n",
        "\n",
        "So will use product dataframe generated by decision tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiQYWXFHZDVD"
      },
      "source": [
        "<h1>Final Predict Function</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2dB8PPukaVY"
      },
      "source": [
        "1. Here our task is to predict the products which are going to be reordered withn in a certain order id.\n",
        "\n",
        "2. So for final predict function it can never expect any new order-id or a new user. As if the order-id or user is new there is no chance of any product being reordered when products are never ordered before.\n",
        "\n",
        "3. This can be seen as cold-start problem.\n",
        "\n",
        "4. So for my final predict function I followed below approach.\n",
        "I took all the prediction from train, validation and test so when a order-id comes and we already have that order-id the function returns list of all the products which can be reordered.\n",
        "\n",
        "5. Still, there was a issue in above approach as I tried to concat train, validaton, test prediction and build a dictionary consisting of order id and product id. But the problem was it was not possible to do so. As it was taking huge amount of time even after I left it to run overnight session got crashed/disconnected itself. So can't use the same approach.\n",
        "\n",
        "6. Time taken last night was\n",
        "13094627it [9:57:59, 127.73it/s]\n",
        "\n",
        "7. So alternative of that I have just taken the test data and predict function work on top of that.\n",
        "\n",
        "8. Since that approach was not working I removed that code to make notebook look more clean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a4lWVO6mbFs"
      },
      "source": [
        "<h1>Function For Prediction</h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fpTUczDi7kW"
      },
      "source": [
        "user_product = final_predict_function(lgb_predicted_df)\n",
        "\n",
        "def pred(order_id, prediction_dict = user_product):    \n",
        "    product_list = user_product.get(order_id,\"The order id does not exist! The user is new so no point of product being reordered\")\n",
        "    return product_list\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0OsgoS9j8_a"
      },
      "source": [
        "products = pd.read_csv('/content/drive/MyDrive/instacart-market-basket-analysis/products.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQbKRMXllV2b"
      },
      "source": [
        "products.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EarN1gysmo8z"
      },
      "source": [
        "test_point_success = pred(2897111)\n",
        "test_point_fail = pred(2897)\n",
        "\n",
        "product_name = list()\n",
        "for i in test_point_success.split(\" \"):\n",
        "    product_name.append(i)\n",
        "\n",
        "product_list = products[products['product_id'].isin(product_name)]['product_name']\n",
        "\n",
        "print(\"Valid Case\")\n",
        "print('Products to be re-ordered are: ')\n",
        "print(product_list)\n",
        "print(\"_\"*80)\n",
        "print(\"Invalid Case\", test_point_fail)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQR6MSl0jOvD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}